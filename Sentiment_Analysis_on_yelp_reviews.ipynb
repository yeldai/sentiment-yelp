{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e743a95f-206d-4ff1-bd9a-56182b754b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\D\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\D\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\D\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\D\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('brown')\n",
    "  \n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import Word\n",
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f6225cf5-b941-4883-8998-38557215688f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r= requests.get(\"https://www.yelp.com/biz/dumpling-baby-china-bistro-san-francisco-4\")\n",
    "\n",
    "soup = BeautifulSoup(r.text,'html.parser')\n",
    "\n",
    "divs = soup.findAll(class_=\"review__373c0__3MsBX\",recursive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c4896afc-f213-4f5d-b6b2-3fa2e5c236b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=[]\n",
    "\n",
    "for div in divs:\n",
    "    reviews.append(div.find('p').text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0e8d69-a532-4536-b60c-75d482f4cab1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Couple Automated Reviews label as \"Elite 2021\", removing and cleaning the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2b07635a-b5f6-4d7b-a6d9-7e7d501aa6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df[\"review\"]==\"Elite 2021\"].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a4762a18-2281-4398-b31a-1324b5ab42a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"word_count\"]=df[\"review\"].apply(lambda x:len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "65c8b856-430a-4016-8c9a-4372d7d4b003",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"char_count\"]=df[\"review\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "25b193e2-b550-4bcc-9c04-a3c47a28f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_words(x):\n",
    "    words=x.split()\n",
    "    return sum(len(word) for word in words)/len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "74f59445-142f-4f23-a221-ba5b42a40137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"average_length_word\"]=df[\"review\"].apply(lambda x: average_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d7ed6d88-b032-48dd-bbd8-725d00159326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\D\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e5426a22-896d-44d9-ae06-58d8d146dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words= stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "98c10a7b-67d9-44d9-9406-69d24e04fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stop_word_count\"]=df[\"review\"].apply(lambda x: len([word for word in x.split() if word.lower()\n",
    "                                  in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3005f96d-e914-4ff9-848c-d16cc9d1a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stopword_rate\"]=df[\"stop_word_count\"]/df[\"word_count\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0ff12532-cca3-45fc-ae7a-db67d15912ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_length_word</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>stopword_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We are repeat customers for their pickup and d...</td>\n",
       "      <td>62</td>\n",
       "      <td>388</td>\n",
       "      <td>5.258065</td>\n",
       "      <td>20</td>\n",
       "      <td>0.322581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This got one star bc we ate it.I have never we...</td>\n",
       "      <td>179</td>\n",
       "      <td>1012</td>\n",
       "      <td>4.653631</td>\n",
       "      <td>79</td>\n",
       "      <td>0.441341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Been curious to try this place since they open...</td>\n",
       "      <td>131</td>\n",
       "      <td>694</td>\n",
       "      <td>4.305344</td>\n",
       "      <td>63</td>\n",
       "      <td>0.480916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I wish I could say only good things, but I wou...</td>\n",
       "      <td>118</td>\n",
       "      <td>578</td>\n",
       "      <td>3.906780</td>\n",
       "      <td>57</td>\n",
       "      <td>0.483051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOVE this place.  Take out only, but that's go...</td>\n",
       "      <td>141</td>\n",
       "      <td>762</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>69</td>\n",
       "      <td>0.489362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  word_count  char_count  \\\n",
       "4  We are repeat customers for their pickup and d...          62         388   \n",
       "1  This got one star bc we ate it.I have never we...         179        1012   \n",
       "6  Been curious to try this place since they open...         131         694   \n",
       "2  I wish I could say only good things, but I wou...         118         578   \n",
       "0  LOVE this place.  Take out only, but that's go...         141         762   \n",
       "\n",
       "   average_length_word  stop_word_count  stopword_rate  \n",
       "4             5.258065               20       0.322581  \n",
       "1             4.653631               79       0.441341  \n",
       "6             4.305344               63       0.480916  \n",
       "2             3.906780               57       0.483051  \n",
       "0             4.333333               69       0.489362  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(\"stopword_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "491b3cb3-5b15-4ca5-b324-1d61231c4556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable        Type                    Data/Info\n",
      "-------------------------------------------------\n",
      "BeautifulSoup   type                    <class 'bs4.BeautifulSoup'>\n",
      "average_words   function                <function average_words at 0x000001E6345FEC10>\n",
      "df              DataFrame                                        <...>      63       0.480916  \n",
      "div             Tag                     <div class=\"review__373c0<...></span></div></div></div>\n",
      "divs            ResultSet               [<div class=\"review__373c<...>/span></div></div></div>]\n",
      "nltk            module                  <module 'nltk' from 'C:\\\\<...>ages\\\\nltk\\\\__init__.py'>\n",
      "np              module                  <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "pd              module                  <module 'pandas' from 'C:<...>es\\\\pandas\\\\__init__.py'>\n",
      "r               Response                <Response [200]>\n",
      "requests        module                  <module 'requests' from '<...>\\\\requests\\\\__init__.py'>\n",
      "reviews         list                    n=10\n",
      "soup            BeautifulSoup           <!DOCTYPE HTML>\\n\\n<!--[i<...>script>\\n</body>\\n</html>\n",
      "stop_words      list                    n=179\n",
      "stopwords       WordListCorpusReader    <WordListCorpusReader in <...>ata\\\\corpora\\\\stopwords'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64742852-295c-4a41-ba2d-3810e6121fc6",
   "metadata": {},
   "source": [
    "### Cleaning the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3bd0b5a3-b7dd-4165-92dd-828b154d42c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review_lower_case_\"]=df[\"review\"].apply(lambda x: \" \".join(word.lower() for word in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "88f5d43b-9798-4abd-9184-8e391c0c2588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review', 'word_count', 'char_count', 'average_length_word',\n",
       "       'stop_word_count', 'stopword_rate', 'review_lower_case_'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d67b9d3d-fb76-48d6-9ea9-e1810c587456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\D\\AppData\\Local\\Temp/ipykernel_3860/3633775387.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"review_lower_case_\"]=df[\"review_lower_case_\"].str.replace(\"[^\\w\\s]\",\" \")\n"
     ]
    }
   ],
   "source": [
    "df[\"review_lower_case_\"]=df[\"review_lower_case_\"].str.replace(\"[^\\w\\s]\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e359d333-542e-4e74-b0a5-5b0cde3da525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stop_words\"]= df[\"review_lower_case_\"].apply(lambda x: \" \".join(word for word in x.split() if word not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b1a046db-c261-438b-8737-c6b86f59391c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_length_word</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>stopword_rate</th>\n",
       "      <th>review_lower_case_</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOVE this place.  Take out only, but that's go...</td>\n",
       "      <td>141</td>\n",
       "      <td>762</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>69</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>love this place  take out only  but that s goo...</td>\n",
       "      <td>love place take good chinese food remember san...</td>\n",
       "      <td>love place take good chinese food remember san...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This got one star bc we ate it.I have never we...</td>\n",
       "      <td>179</td>\n",
       "      <td>1012</td>\n",
       "      <td>4.653631</td>\n",
       "      <td>79</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>this got one star bc we ate it i have never we...</td>\n",
       "      <td>got one star bc ate never went place serves sh...</td>\n",
       "      <td>got star bc ate never went place serves shangh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I wish I could say only good things, but I wou...</td>\n",
       "      <td>118</td>\n",
       "      <td>578</td>\n",
       "      <td>3.906780</td>\n",
       "      <td>57</td>\n",
       "      <td>0.483051</td>\n",
       "      <td>i wish i could say only good things  but i wou...</td>\n",
       "      <td>wish could say good things would careful one o...</td>\n",
       "      <td>wish could say good things careful ordered sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We are repeat customers for their pickup and d...</td>\n",
       "      <td>62</td>\n",
       "      <td>388</td>\n",
       "      <td>5.258065</td>\n",
       "      <td>20</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>we are repeat customers for their pickup and d...</td>\n",
       "      <td>repeat customers pickup delivery favorites cri...</td>\n",
       "      <td>repeat customers pickup delivery favorites cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Been curious to try this place since they open...</td>\n",
       "      <td>131</td>\n",
       "      <td>694</td>\n",
       "      <td>4.305344</td>\n",
       "      <td>63</td>\n",
       "      <td>0.480916</td>\n",
       "      <td>been curious to try this place since they open...</td>\n",
       "      <td>curious try place since opened lazy today deci...</td>\n",
       "      <td>curious try place since opened lazy today deci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  word_count  char_count  \\\n",
       "0  LOVE this place.  Take out only, but that's go...         141         762   \n",
       "1  This got one star bc we ate it.I have never we...         179        1012   \n",
       "2  I wish I could say only good things, but I wou...         118         578   \n",
       "4  We are repeat customers for their pickup and d...          62         388   \n",
       "6  Been curious to try this place since they open...         131         694   \n",
       "\n",
       "   average_length_word  stop_word_count  stopword_rate  \\\n",
       "0             4.333333               69       0.489362   \n",
       "1             4.653631               79       0.441341   \n",
       "2             3.906780               57       0.483051   \n",
       "4             5.258065               20       0.322581   \n",
       "6             4.305344               63       0.480916   \n",
       "\n",
       "                                  review_lower_case_  \\\n",
       "0  love this place  take out only  but that s goo...   \n",
       "1  this got one star bc we ate it i have never we...   \n",
       "2  i wish i could say only good things  but i wou...   \n",
       "4  we are repeat customers for their pickup and d...   \n",
       "6  been curious to try this place since they open...   \n",
       "\n",
       "                                          stop_words  \\\n",
       "0  love place take good chinese food remember san...   \n",
       "1  got one star bc ate never went place serves sh...   \n",
       "2  wish could say good things would careful one o...   \n",
       "4  repeat customers pickup delivery favorites cri...   \n",
       "6  curious try place since opened lazy today deci...   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  love place take good chinese food remember san...  \n",
       "1  got star bc ate never went place serves shangh...  \n",
       "2  wish could say good things careful ordered sup...  \n",
       "4  repeat customers pickup delivery favorites cri...  \n",
       "6  curious try place since opened lazy today deci...  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cleaned_review\"]=df[\"stop_words\"].apply(lambda x: \" \".join(word for word in x.split() if word not in other_stop_words))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3709b31d-c18a-422b-99d3-3ffa74152bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spicy        6\n",
       "food         6\n",
       "place        5\n",
       "suppose      4\n",
       "would        4\n",
       "tofu         4\n",
       "noodles      4\n",
       "ordered      4\n",
       "dumplings    4\n",
       "delivery     4\n",
       "quality      3\n",
       "one          3\n",
       "shanghai     3\n",
       "sauce        3\n",
       "shrimp       3\n",
       "order        3\n",
       "better       3\n",
       "honey        3\n",
       "love         3\n",
       "good         3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(\" \".join(df[\"stop_words\"]).split()).value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d5e376cb-18ee-4f0c-9893-b8ee29cd4c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_stop_words= [\"get\",\"told\",\"would\",\"week\",\"us\",\"test\",\"right\",\"left\",\"one\",\"even\",\"also\",\"go\",\"asked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e9636a64-6802-4f68-b16e-b22b16fb7393",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemmatized\"]=df[\"cleaned_review\"].apply(lambda x: \" \".join(Word(word).lemmatize() for word in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "02f43b6e-5f1c-4957-a8de-7d00fd106248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_length_word</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>stopword_rate</th>\n",
       "      <th>review_lower_case_</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOVE this place.  Take out only, but that's go...</td>\n",
       "      <td>141</td>\n",
       "      <td>762</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>69</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>love this place  take out only  but that s goo...</td>\n",
       "      <td>love place take good chinese food remember san...</td>\n",
       "      <td>love place take good chinese food remember san...</td>\n",
       "      <td>love place take good chinese food remember san...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This got one star bc we ate it.I have never we...</td>\n",
       "      <td>179</td>\n",
       "      <td>1012</td>\n",
       "      <td>4.653631</td>\n",
       "      <td>79</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>this got one star bc we ate it i have never we...</td>\n",
       "      <td>got one star bc ate never went place serves sh...</td>\n",
       "      <td>got star bc ate never went place serves shangh...</td>\n",
       "      <td>got star bc ate never went place serf shanghai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I wish I could say only good things, but I wou...</td>\n",
       "      <td>118</td>\n",
       "      <td>578</td>\n",
       "      <td>3.906780</td>\n",
       "      <td>57</td>\n",
       "      <td>0.483051</td>\n",
       "      <td>i wish i could say only good things  but i wou...</td>\n",
       "      <td>wish could say good things would careful one o...</td>\n",
       "      <td>wish could say good things careful ordered sup...</td>\n",
       "      <td>wish could say good thing careful ordered supe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We are repeat customers for their pickup and d...</td>\n",
       "      <td>62</td>\n",
       "      <td>388</td>\n",
       "      <td>5.258065</td>\n",
       "      <td>20</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>we are repeat customers for their pickup and d...</td>\n",
       "      <td>repeat customers pickup delivery favorites cri...</td>\n",
       "      <td>repeat customers pickup delivery favorites cri...</td>\n",
       "      <td>repeat customer pickup delivery favorite crisp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Been curious to try this place since they open...</td>\n",
       "      <td>131</td>\n",
       "      <td>694</td>\n",
       "      <td>4.305344</td>\n",
       "      <td>63</td>\n",
       "      <td>0.480916</td>\n",
       "      <td>been curious to try this place since they open...</td>\n",
       "      <td>curious try place since opened lazy today deci...</td>\n",
       "      <td>curious try place since opened lazy today deci...</td>\n",
       "      <td>curious try place since opened lazy today deci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  word_count  char_count  \\\n",
       "0  LOVE this place.  Take out only, but that's go...         141         762   \n",
       "1  This got one star bc we ate it.I have never we...         179        1012   \n",
       "2  I wish I could say only good things, but I wou...         118         578   \n",
       "4  We are repeat customers for their pickup and d...          62         388   \n",
       "6  Been curious to try this place since they open...         131         694   \n",
       "\n",
       "   average_length_word  stop_word_count  stopword_rate  \\\n",
       "0             4.333333               69       0.489362   \n",
       "1             4.653631               79       0.441341   \n",
       "2             3.906780               57       0.483051   \n",
       "4             5.258065               20       0.322581   \n",
       "6             4.305344               63       0.480916   \n",
       "\n",
       "                                  review_lower_case_  \\\n",
       "0  love this place  take out only  but that s goo...   \n",
       "1  this got one star bc we ate it i have never we...   \n",
       "2  i wish i could say only good things  but i wou...   \n",
       "4  we are repeat customers for their pickup and d...   \n",
       "6  been curious to try this place since they open...   \n",
       "\n",
       "                                          stop_words  \\\n",
       "0  love place take good chinese food remember san...   \n",
       "1  got one star bc ate never went place serves sh...   \n",
       "2  wish could say good things would careful one o...   \n",
       "4  repeat customers pickup delivery favorites cri...   \n",
       "6  curious try place since opened lazy today deci...   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  love place take good chinese food remember san...   \n",
       "1  got star bc ate never went place serves shangh...   \n",
       "2  wish could say good things careful ordered sup...   \n",
       "4  repeat customers pickup delivery favorites cri...   \n",
       "6  curious try place since opened lazy today deci...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  love place take good chinese food remember san...  \n",
       "1  got star bc ate never went place serf shanghai...  \n",
       "2  wish could say good thing careful ordered supe...  \n",
       "4  repeat customer pickup delivery favorite crisp...  \n",
       "6  curious try place since opened lazy today deci...  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9718af3d-0f5f-47c8-a9b0-9332d561869e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love place take good chinese food remember san franciso long ago many great chinese restaurants recent years struggle find consistent quality deliciousness ordered dishes first visit including walnut shrimp outstanding use crack could eat whole plate give many big juicy shrimp room want hungry enjoy much excellent flavors generous balance protein veggies love chinese restaurant lumpia shanghai menu yummy wait next carb night'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cleaned_review\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "77b27520-8d83-4cab-a264-73f293b25077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love place take good chinese food remember san franciso long ago many great chinese restaurant recent year struggle find consistent quality deliciousness ordered dish first visit including walnut shrimp outstanding use crack could eat whole plate give many big juicy shrimp room want hungry enjoy much excellent flavor generous balance protein veggie love chinese restaurant lumpia shanghai menu yummy wait next carb night'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lemmatized\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65592701-6bab-48ca-9ba7-f3f42c6a0b8d",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f4f94892-abf1-4d80-8187-9da2229a5ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\D\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\D\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmatized'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "1019604c-40a9-440d-8960-fefb30822f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['polarity']=df[\"lemmatized\"].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "df['subjectivty']=df[\"lemmatized\"].apply(lambda x: TextBlob(x).sentiment[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "ca5f37bf-22d6-4512-bf7f-aed3fea3b849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_length_word</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>stopword_rate</th>\n",
       "      <th>review_lower_case_</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>tags</th>\n",
       "      <th>noun_phrase</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOVE this place.  Take out only, but that's go...</td>\n",
       "      <td>141</td>\n",
       "      <td>762</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>69</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>love this place  take out only  but that s goo...</td>\n",
       "      <td>love place take good chinese food remember san...</td>\n",
       "      <td>love place take good chinese food remember san...</td>\n",
       "      <td>love place take good chinese food remember san...</td>\n",
       "      <td>[(love, VB), (place, NN), (take, VB), (good, J...</td>\n",
       "      <td>[good chinese food, san franciso, great chines...</td>\n",
       "      <td>0.318421</td>\n",
       "      <td>0.403070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This got one star bc we ate it.I have never we...</td>\n",
       "      <td>179</td>\n",
       "      <td>1012</td>\n",
       "      <td>4.653631</td>\n",
       "      <td>79</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>this got one star bc we ate it i have never we...</td>\n",
       "      <td>got one star bc ate never went place serves sh...</td>\n",
       "      <td>got star bc ate never went place serves shangh...</td>\n",
       "      <td>got star bc ate never went place serf shanghai...</td>\n",
       "      <td>[(got, VBD), (star, NN), (bc, NN), (ate, NN), ...</td>\n",
       "      <td>[star bc ate, place serf shanghai noodle didnt...</td>\n",
       "      <td>0.056481</td>\n",
       "      <td>0.523148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I wish I could say only good things, but I wou...</td>\n",
       "      <td>118</td>\n",
       "      <td>578</td>\n",
       "      <td>3.906780</td>\n",
       "      <td>57</td>\n",
       "      <td>0.483051</td>\n",
       "      <td>i wish i could say only good things  but i wou...</td>\n",
       "      <td>wish could say good things would careful one o...</td>\n",
       "      <td>wish could say good things careful ordered sup...</td>\n",
       "      <td>wish could say good thing careful ordered supe...</td>\n",
       "      <td>[(wish, NN), (could, MD), (say, VB), (good, JJ...</td>\n",
       "      <td>[good thing, taste food chow hair, taste rotte...</td>\n",
       "      <td>0.012670</td>\n",
       "      <td>0.618169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We are repeat customers for their pickup and d...</td>\n",
       "      <td>62</td>\n",
       "      <td>388</td>\n",
       "      <td>5.258065</td>\n",
       "      <td>20</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>we are repeat customers for their pickup and d...</td>\n",
       "      <td>repeat customers pickup delivery favorites cri...</td>\n",
       "      <td>repeat customers pickup delivery favorites cri...</td>\n",
       "      <td>repeat customer pickup delivery favorite crisp...</td>\n",
       "      <td>[(repeat, NN), (customer, NN), (pickup, NN), (...</td>\n",
       "      <td>[repeat customer pickup delivery, favorite cri...</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Been curious to try this place since they open...</td>\n",
       "      <td>131</td>\n",
       "      <td>694</td>\n",
       "      <td>4.305344</td>\n",
       "      <td>63</td>\n",
       "      <td>0.480916</td>\n",
       "      <td>been curious to try this place since they open...</td>\n",
       "      <td>curious try place since opened lazy today deci...</td>\n",
       "      <td>curious try place since opened lazy today deci...</td>\n",
       "      <td>curious try place since opened lazy today deci...</td>\n",
       "      <td>[(curious, JJ), (try, NN), (place, NN), (since...</td>\n",
       "      <td>[order delivery, easy delivery, overall food, ...</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.605952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  word_count  char_count  \\\n",
       "0  LOVE this place.  Take out only, but that's go...         141         762   \n",
       "1  This got one star bc we ate it.I have never we...         179        1012   \n",
       "2  I wish I could say only good things, but I wou...         118         578   \n",
       "4  We are repeat customers for their pickup and d...          62         388   \n",
       "6  Been curious to try this place since they open...         131         694   \n",
       "\n",
       "   average_length_word  stop_word_count  stopword_rate  \\\n",
       "0             4.333333               69       0.489362   \n",
       "1             4.653631               79       0.441341   \n",
       "2             3.906780               57       0.483051   \n",
       "4             5.258065               20       0.322581   \n",
       "6             4.305344               63       0.480916   \n",
       "\n",
       "                                  review_lower_case_  \\\n",
       "0  love this place  take out only  but that s goo...   \n",
       "1  this got one star bc we ate it i have never we...   \n",
       "2  i wish i could say only good things  but i wou...   \n",
       "4  we are repeat customers for their pickup and d...   \n",
       "6  been curious to try this place since they open...   \n",
       "\n",
       "                                          stop_words  \\\n",
       "0  love place take good chinese food remember san...   \n",
       "1  got one star bc ate never went place serves sh...   \n",
       "2  wish could say good things would careful one o...   \n",
       "4  repeat customers pickup delivery favorites cri...   \n",
       "6  curious try place since opened lazy today deci...   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  love place take good chinese food remember san...   \n",
       "1  got star bc ate never went place serves shangh...   \n",
       "2  wish could say good things careful ordered sup...   \n",
       "4  repeat customers pickup delivery favorites cri...   \n",
       "6  curious try place since opened lazy today deci...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  love place take good chinese food remember san...   \n",
       "1  got star bc ate never went place serf shanghai...   \n",
       "2  wish could say good thing careful ordered supe...   \n",
       "4  repeat customer pickup delivery favorite crisp...   \n",
       "6  curious try place since opened lazy today deci...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [(love, VB), (place, NN), (take, VB), (good, J...   \n",
       "1  [(got, VBD), (star, NN), (bc, NN), (ate, NN), ...   \n",
       "2  [(wish, NN), (could, MD), (say, VB), (good, JJ...   \n",
       "4  [(repeat, NN), (customer, NN), (pickup, NN), (...   \n",
       "6  [(curious, JJ), (try, NN), (place, NN), (since...   \n",
       "\n",
       "                                         noun_phrase  polarity  subjectivty  \n",
       "0  [good chinese food, san franciso, great chines...  0.318421     0.403070  \n",
       "1  [star bc ate, place serf shanghai noodle didnt...  0.056481     0.523148  \n",
       "2  [good thing, taste food chow hair, taste rotte...  0.012670     0.618169  \n",
       "4  [repeat customer pickup delivery, favorite cri...  0.135000     0.710000  \n",
       "6  [order delivery, easy delivery, overall food, ...  0.278571     0.605952  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b00e39-898e-444e-a11e-32445cc7f515",
   "metadata": {},
   "source": [
    "## As expected teh reviews are quite subjective\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229a3eb9-d9f1-4436-97da-64bd729a0143",
   "metadata": {},
   "source": [
    "## However, just interested on whether noun_phares are effecting polarity and subjectivity ? Not really"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4ce7594d-6815-4d69-ab05-a7c6b88fc48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_length_word</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>stopword_rate</th>\n",
       "      <th>review_lower_case_</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>tags</th>\n",
       "      <th>noun_phrase</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivty</th>\n",
       "      <th>noun_phrase_polarity</th>\n",
       "      <th>noun_phrase_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOVE this place.  Take out only, but that's go...</td>\n",
       "      <td>141</td>\n",
       "      <td>762</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>69</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>love this place  take out only  but that s goo...</td>\n",
       "      <td>love place take good chinese food remember san...</td>\n",
       "      <td>love place take good chinese food remember san...</td>\n",
       "      <td>love place take good chinese food remember san...</td>\n",
       "      <td>[(love, VB), (place, NN), (take, VB), (good, J...</td>\n",
       "      <td>[good chinese food, san franciso, great chines...</td>\n",
       "      <td>0.318421</td>\n",
       "      <td>0.403070</td>\n",
       "      <td>0.318421</td>\n",
       "      <td>0.403070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This got one star bc we ate it.I have never we...</td>\n",
       "      <td>179</td>\n",
       "      <td>1012</td>\n",
       "      <td>4.653631</td>\n",
       "      <td>79</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>this got one star bc we ate it i have never we...</td>\n",
       "      <td>got one star bc ate never went place serves sh...</td>\n",
       "      <td>got star bc ate never went place serves shangh...</td>\n",
       "      <td>got star bc ate never went place serf shanghai...</td>\n",
       "      <td>[(got, VBD), (star, NN), (bc, NN), (ate, NN), ...</td>\n",
       "      <td>[star bc ate, place serf shanghai noodle didnt...</td>\n",
       "      <td>0.056481</td>\n",
       "      <td>0.523148</td>\n",
       "      <td>0.056481</td>\n",
       "      <td>0.523148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I wish I could say only good things, but I wou...</td>\n",
       "      <td>118</td>\n",
       "      <td>578</td>\n",
       "      <td>3.906780</td>\n",
       "      <td>57</td>\n",
       "      <td>0.483051</td>\n",
       "      <td>i wish i could say only good things  but i wou...</td>\n",
       "      <td>wish could say good things would careful one o...</td>\n",
       "      <td>wish could say good things careful ordered sup...</td>\n",
       "      <td>wish could say good thing careful ordered supe...</td>\n",
       "      <td>[(wish, NN), (could, MD), (say, VB), (good, JJ...</td>\n",
       "      <td>[good thing, taste food chow hair, taste rotte...</td>\n",
       "      <td>0.012670</td>\n",
       "      <td>0.618169</td>\n",
       "      <td>0.012670</td>\n",
       "      <td>0.618169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We are repeat customers for their pickup and d...</td>\n",
       "      <td>62</td>\n",
       "      <td>388</td>\n",
       "      <td>5.258065</td>\n",
       "      <td>20</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>we are repeat customers for their pickup and d...</td>\n",
       "      <td>repeat customers pickup delivery favorites cri...</td>\n",
       "      <td>repeat customers pickup delivery favorites cri...</td>\n",
       "      <td>repeat customer pickup delivery favorite crisp...</td>\n",
       "      <td>[(repeat, NN), (customer, NN), (pickup, NN), (...</td>\n",
       "      <td>[repeat customer pickup delivery, favorite cri...</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Been curious to try this place since they open...</td>\n",
       "      <td>131</td>\n",
       "      <td>694</td>\n",
       "      <td>4.305344</td>\n",
       "      <td>63</td>\n",
       "      <td>0.480916</td>\n",
       "      <td>been curious to try this place since they open...</td>\n",
       "      <td>curious try place since opened lazy today deci...</td>\n",
       "      <td>curious try place since opened lazy today deci...</td>\n",
       "      <td>curious try place since opened lazy today deci...</td>\n",
       "      <td>[(curious, JJ), (try, NN), (place, NN), (since...</td>\n",
       "      <td>[order delivery, easy delivery, overall food, ...</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.605952</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.605952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  word_count  char_count  \\\n",
       "0  LOVE this place.  Take out only, but that's go...         141         762   \n",
       "1  This got one star bc we ate it.I have never we...         179        1012   \n",
       "2  I wish I could say only good things, but I wou...         118         578   \n",
       "4  We are repeat customers for their pickup and d...          62         388   \n",
       "6  Been curious to try this place since they open...         131         694   \n",
       "\n",
       "   average_length_word  stop_word_count  stopword_rate  \\\n",
       "0             4.333333               69       0.489362   \n",
       "1             4.653631               79       0.441341   \n",
       "2             3.906780               57       0.483051   \n",
       "4             5.258065               20       0.322581   \n",
       "6             4.305344               63       0.480916   \n",
       "\n",
       "                                  review_lower_case_  \\\n",
       "0  love this place  take out only  but that s goo...   \n",
       "1  this got one star bc we ate it i have never we...   \n",
       "2  i wish i could say only good things  but i wou...   \n",
       "4  we are repeat customers for their pickup and d...   \n",
       "6  been curious to try this place since they open...   \n",
       "\n",
       "                                          stop_words  \\\n",
       "0  love place take good chinese food remember san...   \n",
       "1  got one star bc ate never went place serves sh...   \n",
       "2  wish could say good things would careful one o...   \n",
       "4  repeat customers pickup delivery favorites cri...   \n",
       "6  curious try place since opened lazy today deci...   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  love place take good chinese food remember san...   \n",
       "1  got star bc ate never went place serves shangh...   \n",
       "2  wish could say good things careful ordered sup...   \n",
       "4  repeat customers pickup delivery favorites cri...   \n",
       "6  curious try place since opened lazy today deci...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  love place take good chinese food remember san...   \n",
       "1  got star bc ate never went place serf shanghai...   \n",
       "2  wish could say good thing careful ordered supe...   \n",
       "4  repeat customer pickup delivery favorite crisp...   \n",
       "6  curious try place since opened lazy today deci...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [(love, VB), (place, NN), (take, VB), (good, J...   \n",
       "1  [(got, VBD), (star, NN), (bc, NN), (ate, NN), ...   \n",
       "2  [(wish, NN), (could, MD), (say, VB), (good, JJ...   \n",
       "4  [(repeat, NN), (customer, NN), (pickup, NN), (...   \n",
       "6  [(curious, JJ), (try, NN), (place, NN), (since...   \n",
       "\n",
       "                                         noun_phrase  polarity  subjectivty  \\\n",
       "0  [good chinese food, san franciso, great chines...  0.318421     0.403070   \n",
       "1  [star bc ate, place serf shanghai noodle didnt...  0.056481     0.523148   \n",
       "2  [good thing, taste food chow hair, taste rotte...  0.012670     0.618169   \n",
       "4  [repeat customer pickup delivery, favorite cri...  0.135000     0.710000   \n",
       "6  [order delivery, easy delivery, overall food, ...  0.278571     0.605952   \n",
       "\n",
       "   noun_phrase_polarity  noun_phrase_subjectivity  \n",
       "0              0.318421                  0.403070  \n",
       "1              0.056481                  0.523148  \n",
       "2              0.012670                  0.618169  \n",
       "4              0.135000                  0.710000  \n",
       "6              0.278571                  0.605952  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['noun_phrase']=df[\"lemmatized\"].apply(lambda x: TextBlob(x).noun_phrases)\n",
    "df['noun_phrase_polarity']=df[\"lemmatized\"].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "df['noun_phrase_subjectivity']=df[\"lemmatized\"].apply(lambda x: TextBlob(x).sentiment[1])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8747c659-bf29-4dc2-9eb4-045024cc20c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_length_word</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>stopword_rate</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivty</th>\n",
       "      <th>noun_phrase_polarity</th>\n",
       "      <th>noun_phrase_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>126.200000</td>\n",
       "      <td>686.800000</td>\n",
       "      <td>4.491430</td>\n",
       "      <td>57.600000</td>\n",
       "      <td>0.443450</td>\n",
       "      <td>0.160229</td>\n",
       "      <td>0.572068</td>\n",
       "      <td>0.160229</td>\n",
       "      <td>0.572068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.481761</td>\n",
       "      <td>230.532427</td>\n",
       "      <td>0.503854</td>\n",
       "      <td>22.534418</td>\n",
       "      <td>0.070167</td>\n",
       "      <td>0.134353</td>\n",
       "      <td>0.115382</td>\n",
       "      <td>0.134353</td>\n",
       "      <td>0.115382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>3.906780</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.012670</td>\n",
       "      <td>0.403070</td>\n",
       "      <td>0.012670</td>\n",
       "      <td>0.403070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>118.000000</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>4.305344</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>0.056481</td>\n",
       "      <td>0.523148</td>\n",
       "      <td>0.056481</td>\n",
       "      <td>0.523148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>131.000000</td>\n",
       "      <td>694.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.480916</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.605952</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.605952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>141.000000</td>\n",
       "      <td>762.000000</td>\n",
       "      <td>4.653631</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.483051</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.618169</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.618169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>179.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>5.258065</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.318421</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.318421</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_count   char_count  average_length_word  stop_word_count  \\\n",
       "count    5.000000     5.000000             5.000000         5.000000   \n",
       "mean   126.200000   686.800000             4.491430        57.600000   \n",
       "std     42.481761   230.532427             0.503854        22.534418   \n",
       "min     62.000000   388.000000             3.906780        20.000000   \n",
       "25%    118.000000   578.000000             4.305344        57.000000   \n",
       "50%    131.000000   694.000000             4.333333        63.000000   \n",
       "75%    141.000000   762.000000             4.653631        69.000000   \n",
       "max    179.000000  1012.000000             5.258065        79.000000   \n",
       "\n",
       "       stopword_rate  polarity  subjectivty  noun_phrase_polarity  \\\n",
       "count       5.000000  5.000000     5.000000              5.000000   \n",
       "mean        0.443450  0.160229     0.572068              0.160229   \n",
       "std         0.070167  0.134353     0.115382              0.134353   \n",
       "min         0.322581  0.012670     0.403070              0.012670   \n",
       "25%         0.441341  0.056481     0.523148              0.056481   \n",
       "50%         0.480916  0.135000     0.605952              0.135000   \n",
       "75%         0.483051  0.278571     0.618169              0.278571   \n",
       "max         0.489362  0.318421     0.710000              0.318421   \n",
       "\n",
       "       noun_phrase_subjectivity  \n",
       "count                  5.000000  \n",
       "mean                   0.572068  \n",
       "std                    0.115382  \n",
       "min                    0.403070  \n",
       "25%                    0.523148  \n",
       "50%                    0.605952  \n",
       "75%                    0.618169  \n",
       "max                    0.710000  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a25ce280-984b-401e-b168-0dbc9bc38b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['good chinese food', 'san franciso', 'great chinese restaurant', 'recent year struggle', 'consistent quality deliciousness', 'walnut shrimp', 'outstanding use', 'whole plate', 'big juicy shrimp room', 'excellent flavor', 'generous balance protein veggie', 'chinese restaurant lumpia shanghai menu yummy', 'carb night'])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"noun_phrase\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "c3fd4f06-9efd-4fa6-859b-417e490c4b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_length_word</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>stopword_rate</th>\n",
       "      <th>review_lower_case_</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>tags</th>\n",
       "      <th>noun_phrase</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivty</th>\n",
       "      <th>noun_phrase_polarity</th>\n",
       "      <th>noun_phrase_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOVE this place.  Take out only, but that's go...</td>\n",
       "      <td>141</td>\n",
       "      <td>762</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>69</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>love this place  take out only  but that s goo...</td>\n",
       "      <td>love place take good chinese food remember san...</td>\n",
       "      <td>love place take good chinese food remember san...</td>\n",
       "      <td>love place take good chinese food remember san...</td>\n",
       "      <td>[(love, VB), (place, NN), (take, VB), (good, J...</td>\n",
       "      <td>[good chinese food, san franciso, great chines...</td>\n",
       "      <td>0.318421</td>\n",
       "      <td>0.403070</td>\n",
       "      <td>0.318421</td>\n",
       "      <td>0.403070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Been curious to try this place since they open...</td>\n",
       "      <td>131</td>\n",
       "      <td>694</td>\n",
       "      <td>4.305344</td>\n",
       "      <td>63</td>\n",
       "      <td>0.480916</td>\n",
       "      <td>been curious to try this place since they open...</td>\n",
       "      <td>curious try place since opened lazy today deci...</td>\n",
       "      <td>curious try place since opened lazy today deci...</td>\n",
       "      <td>curious try place since opened lazy today deci...</td>\n",
       "      <td>[(curious, JJ), (try, NN), (place, NN), (since...</td>\n",
       "      <td>[order delivery, easy delivery, overall food, ...</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.605952</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.605952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We are repeat customers for their pickup and d...</td>\n",
       "      <td>62</td>\n",
       "      <td>388</td>\n",
       "      <td>5.258065</td>\n",
       "      <td>20</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>we are repeat customers for their pickup and d...</td>\n",
       "      <td>repeat customers pickup delivery favorites cri...</td>\n",
       "      <td>repeat customers pickup delivery favorites cri...</td>\n",
       "      <td>repeat customer pickup delivery favorite crisp...</td>\n",
       "      <td>[(repeat, NN), (customer, NN), (pickup, NN), (...</td>\n",
       "      <td>[repeat customer pickup delivery, favorite cri...</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This got one star bc we ate it.I have never we...</td>\n",
       "      <td>179</td>\n",
       "      <td>1012</td>\n",
       "      <td>4.653631</td>\n",
       "      <td>79</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>this got one star bc we ate it i have never we...</td>\n",
       "      <td>got one star bc ate never went place serves sh...</td>\n",
       "      <td>got star bc ate never went place serves shangh...</td>\n",
       "      <td>got star bc ate never went place serf shanghai...</td>\n",
       "      <td>[(got, VBD), (star, NN), (bc, NN), (ate, NN), ...</td>\n",
       "      <td>[star bc ate, place serf shanghai noodle didnt...</td>\n",
       "      <td>0.056481</td>\n",
       "      <td>0.523148</td>\n",
       "      <td>0.056481</td>\n",
       "      <td>0.523148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I wish I could say only good things, but I wou...</td>\n",
       "      <td>118</td>\n",
       "      <td>578</td>\n",
       "      <td>3.906780</td>\n",
       "      <td>57</td>\n",
       "      <td>0.483051</td>\n",
       "      <td>i wish i could say only good things  but i wou...</td>\n",
       "      <td>wish could say good things would careful one o...</td>\n",
       "      <td>wish could say good things careful ordered sup...</td>\n",
       "      <td>wish could say good thing careful ordered supe...</td>\n",
       "      <td>[(wish, NN), (could, MD), (say, VB), (good, JJ...</td>\n",
       "      <td>[good thing, taste food chow hair, taste rotte...</td>\n",
       "      <td>0.012670</td>\n",
       "      <td>0.618169</td>\n",
       "      <td>0.012670</td>\n",
       "      <td>0.618169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  word_count  char_count  \\\n",
       "0  LOVE this place.  Take out only, but that's go...         141         762   \n",
       "6  Been curious to try this place since they open...         131         694   \n",
       "4  We are repeat customers for their pickup and d...          62         388   \n",
       "1  This got one star bc we ate it.I have never we...         179        1012   \n",
       "2  I wish I could say only good things, but I wou...         118         578   \n",
       "\n",
       "   average_length_word  stop_word_count  stopword_rate  \\\n",
       "0             4.333333               69       0.489362   \n",
       "6             4.305344               63       0.480916   \n",
       "4             5.258065               20       0.322581   \n",
       "1             4.653631               79       0.441341   \n",
       "2             3.906780               57       0.483051   \n",
       "\n",
       "                                  review_lower_case_  \\\n",
       "0  love this place  take out only  but that s goo...   \n",
       "6  been curious to try this place since they open...   \n",
       "4  we are repeat customers for their pickup and d...   \n",
       "1  this got one star bc we ate it i have never we...   \n",
       "2  i wish i could say only good things  but i wou...   \n",
       "\n",
       "                                          stop_words  \\\n",
       "0  love place take good chinese food remember san...   \n",
       "6  curious try place since opened lazy today deci...   \n",
       "4  repeat customers pickup delivery favorites cri...   \n",
       "1  got one star bc ate never went place serves sh...   \n",
       "2  wish could say good things would careful one o...   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  love place take good chinese food remember san...   \n",
       "6  curious try place since opened lazy today deci...   \n",
       "4  repeat customers pickup delivery favorites cri...   \n",
       "1  got star bc ate never went place serves shangh...   \n",
       "2  wish could say good things careful ordered sup...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  love place take good chinese food remember san...   \n",
       "6  curious try place since opened lazy today deci...   \n",
       "4  repeat customer pickup delivery favorite crisp...   \n",
       "1  got star bc ate never went place serf shanghai...   \n",
       "2  wish could say good thing careful ordered supe...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [(love, VB), (place, NN), (take, VB), (good, J...   \n",
       "6  [(curious, JJ), (try, NN), (place, NN), (since...   \n",
       "4  [(repeat, NN), (customer, NN), (pickup, NN), (...   \n",
       "1  [(got, VBD), (star, NN), (bc, NN), (ate, NN), ...   \n",
       "2  [(wish, NN), (could, MD), (say, VB), (good, JJ...   \n",
       "\n",
       "                                         noun_phrase  polarity  subjectivty  \\\n",
       "0  [good chinese food, san franciso, great chines...  0.318421     0.403070   \n",
       "6  [order delivery, easy delivery, overall food, ...  0.278571     0.605952   \n",
       "4  [repeat customer pickup delivery, favorite cri...  0.135000     0.710000   \n",
       "1  [star bc ate, place serf shanghai noodle didnt...  0.056481     0.523148   \n",
       "2  [good thing, taste food chow hair, taste rotte...  0.012670     0.618169   \n",
       "\n",
       "   noun_phrase_polarity  noun_phrase_subjectivity  \n",
       "0              0.318421                  0.403070  \n",
       "6              0.278571                  0.605952  \n",
       "4              0.135000                  0.710000  \n",
       "1              0.056481                  0.523148  \n",
       "2              0.012670                  0.618169  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"polarity\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e80b1a-ef43-41ca-910a-fd5515e3cdae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
